Manually assigning topics can be an error-prone activity that can lead to 
wrongly specified tags. Over the last years, several attempts have been 
made to \textit{classify} \GH projects by automatically inferring 
appropriate topics. In the context of data mining, \textit{classification} is 
one of the critical operations that are used to dig deep into available data 
for gaining knowledge and for identifying repetitive 
patterns~\cite{kotsiantis2007supervised}. 



\smallskip

With the aim of contributing the resolution of the problem of recommending \GH 
topics, in the next section we propose to use item-based collaborative filtering to recommend relevant topics. The  
challenges that we had to cope with for evaluating its performance are mainly 
the following ones:

\vspace{.2cm}
\noindent
$\triangleright$ \emph{Dataset definition:} the creation of the datasets to be 
used for evaluating the approach being proposed and comparing it with some 
baseline is a daunting task: repositories might be moved, heavily changed or 
even deleted during the initial creation. Thus, the crawling activity can be 
negatively affected by these continuous changes and lead to lack of data, and 
poor topic coverage. GHTorrent\footnote{\url{http://ghtorrent.org/}} tries to 
mitigate this issue by offering daily dumps of the repositories' metadata. 
However, this kind of data might not be enough or even appropriate (\eg source 
code is not available in GHTorrent dumps) to properly classify  an entire 
repository.	Even considering directly \GH data can be difficult: \GH limits the 
total number of requests per hour to 5,000 for authenticated users and 60 for 
unauthorized requests. Considering all these constraints, building a suitable 
dataset represents a real challenge to be managed carefully.
	
\vspace{.2cm}
\noindent
$\triangleright$ \emph{Topics distribution:} although tags can be assigned only 
by the owners of \GH repositories, users can potentially wrongly specify topics 
or introduce information overload by inserting too many elements. Thus, 
creating a reliable ground truth to assess the classification performance of 
the proposed approach represents another relevant difficulty. 