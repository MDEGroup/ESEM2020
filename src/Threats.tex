
This section discusses the threats that may affect the results of the evaluation. We also list the countermeasures taken to minimize these issues.

The \emph{internal validity} could be compromised by the dataset features, \ie the number of projects for each topic, the number of outcomes. We tackle this issue by variating the aforementioned parameters to build datasets with different characteristics. In this way, several scenarios are used to evaluate \TF's overall performances.

\emph{External validity} concerns the rationale behind the selection of the \GH repository used in the assessment. As stated in the related section, we download randomly repositories by imposing the quality filter on the stars. Nevertheless, some repositories could be tagged with topics that can affect the quality of the graph computed in the data extraction phase. To be concrete, a user can label its repository using terms that are not enough descriptive \ie using infrequent or duplicated terms in the topic list. To deal with this issue, we apply the topic filter as stated in Section \ref{sec:filter} to reduce the possible noise during the graph building.

Threats to \emph{construction validity} concerns the choice of \MNB as the baseline in the conducted experiment. First of all, the availability of the replication package allows a more comprehensive evaluation rather than other approaches. As we claimed before, the two approaches are strongly different from the construction point of view including the recommendation engine and data extraction components. To make the comparison as fair as possible, we run \MNB on the same datasets by adapting the overall structure for the ten folder validation.